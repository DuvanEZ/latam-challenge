{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este archivo puedes escribir lo que estimes conveniente. Te recomendamos detallar tu solución y todas las suposiciones que estás considerando. Aquí puedes ejecutar las funciones que definiste en los otros archivos de la carpeta src, medir el tiempo, memoria, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file exists.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "file_path = r\"\\Users\\DZWorld2\\Documents\\Studying\\challenge_option\\tweets.json\\farmers-protest-tweets-2021-2-4.json\"\n",
    "# Ensure the file path is correctly formatted for Windows\n",
    "file_path = file_path.replace(\"\\\\\", \"/\")\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(file_path):\n",
    "    print(\"The file exists.\")\n",
    "else:\n",
    "    \n",
    "    print(\"The file does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "from collections import defaultdict, Counter\n",
    "from typing import List, Tuple, Generator, Dict\n",
    "# We this function to read the tweets from the file using a generator because im going to supose that the file is large and we dont want to load all the tweets into memory at once make it more memory efficient\n",
    "def read_tweets(file_path: str):\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            \n",
    "            yield json.loads(line)\n",
    "\n",
    "def q1_memory(file_path: str) -> List[Tuple[datetime.date, str, int]]:\n",
    "    tweet_counts_per_date = Counter()\n",
    "    user_tweets_per_date = defaultdict(lambda: Counter())\n",
    "\n",
    "    # Step 1 & 2: Read and process each tweet\n",
    "    for tweet in read_tweets(file_path):\n",
    "        date = datetime.strptime(tweet['date'], '%Y-%m-%dT%H:%M:%S%z').date()\n",
    "        user = tweet['user']['username']\n",
    "        tweet_counts_per_date[date] += 1\n",
    "        user_tweets_per_date[date][user] += 1\n",
    "\n",
    "    # Step 3 & 4: Identify top 10 dates\n",
    "    top_10_dates = [date for date, _ in tweet_counts_per_date.most_common(10)]\n",
    "\n",
    "    # Step 5: For each top date, find the user with the most tweets\n",
    "    top_users = [(date, user_tweets.most_common(1)[0][0], user_tweets.most_common(1)[0][1]) for date, user_tweets in user_tweets_per_date.items() if date in top_10_dates]\n",
    "\n",
    "    # Sort the result by date as the final step\n",
    "    top_users_sorted = sorted(top_users, key=lambda x: x[0])\n",
    "\n",
    "    return top_users_sorted\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(datetime.date(2021, 2, 12), 'RanbirS00614606', 176), (datetime.date(2021, 2, 13), 'MaanDee08215437', 178), (datetime.date(2021, 2, 14), 'rebelpacifist', 119), (datetime.date(2021, 2, 15), 'jot__b', 134), (datetime.date(2021, 2, 16), 'jot__b', 133), (datetime.date(2021, 2, 17), 'RaaJVinderkaur', 185), (datetime.date(2021, 2, 18), 'neetuanjle_nitu', 195), (datetime.date(2021, 2, 19), 'Preetm91', 267), (datetime.date(2021, 2, 20), 'MangalJ23056160', 108), (datetime.date(2021, 2, 23), 'Surrypuria', 135)]\n"
     ]
    }
   ],
   "source": [
    "print(q1_memory(file_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import q1_memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_q1_memory = q1_memory.q1_memory(file_path)\n",
    "result_q1_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.77 s ± 34.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit q1_memory(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 461.33 MiB, increment: 1.70 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit q1_memory(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def q1_time(file_path: str) -> List[Tuple[datetime.date, str, int]]:\n",
    "    try:\n",
    "        with open(file_path, 'r') as json_file:\n",
    "            # Cargar archivo json linea a linea\n",
    "            data = [json.loads(line.strip()) for line in json_file]\n",
    "        # Usar una list comprehension para extraer los campos\n",
    "        data = [(item['date'], item['user']['username'], item['id']) for item in data if 'date' in item and 'user' in item and 'id' in item and 'username' in item['user']]\n",
    "\n",
    "        # Convertir la lista de tuplas en un dataframe de pandas\n",
    "        df = pd.DataFrame(data, columns=['date', 'user', 'id'])\n",
    "        \n",
    "        # Convertir campo date en formato datetime\n",
    "        df['date'] = pd.to_datetime(df['date']).dt.date\n",
    "\n",
    "        tweet_counts = df.groupby('date').size()\n",
    "        top_10_dates = tweet_counts.nlargest(10).index\n",
    "        df_top_10 = df[df['date'].isin(top_10_dates)]\n",
    "        top_users = df_top_10.groupby('date')['user'].agg(lambda x: x.value_counts().index[0])\n",
    "\n",
    "        # Convertir el resultado en una lista de tuplas\n",
    "        result = [(date, user) for date, user in zip(top_10_dates, top_users)]\n",
    "        \n",
    "        return result\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file {file_path} was not found.\")\n",
    "        return []\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Error decoding JSON.\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(datetime.date(2021, 2, 12), 'RanbirS00614606'), (datetime.date(2021, 2, 13), 'MaanDee08215437'), (datetime.date(2021, 2, 17), 'rebelpacifist'), (datetime.date(2021, 2, 16), 'jot__b'), (datetime.date(2021, 2, 14), 'jot__b'), (datetime.date(2021, 2, 18), 'RaaJVinderkaur'), (datetime.date(2021, 2, 15), 'neetuanjle_nitu'), (datetime.date(2021, 2, 20), 'Preetm91'), (datetime.date(2021, 2, 23), 'MangalJ23056160'), (datetime.date(2021, 2, 19), 'Surrypuria')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "result_q1_fast = q1_time(file_path)\n",
    "print(result_q1_fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n"
     ]
    }
   ],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.76 s ± 199 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit q1_time(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\n",
      "  Using cached pyspark-3.5.1-py2.py3-none-any.whl\n",
      "Collecting py4j==0.10.9.7\n",
      "  Using cached py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9.7 pyspark-3.5.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from datetime import date\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, to_date, count, row_number\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "def q1_time_spark(file_path: str) -> List[Tuple[date, str, int]]:\n",
    "    try:\n",
    "      # Initialize Spark session\n",
    "      spark = SparkSession.builder.appName(\"Q1Time\").getOrCreate()\n",
    "\n",
    "      # Read JSON file\n",
    "      df = spark.read.json(file_path)\n",
    "\n",
    "      # Filter out rows with missing fields\n",
    "      df_filtered = df.filter(\"date IS NOT NULL AND user IS NOT NULL AND id IS NOT NULL AND user.username IS NOT NULL\")\n",
    "\n",
    "      # Select and rename fields\n",
    "      df_selected = df_filtered.select(to_date(col(\"date\")).alias(\"date\"), col(\"user.username\").alias(\"user\"), col(\"id\"))\n",
    "\n",
    "      # Count tweets per date and get top 10 dates\n",
    "      top_dates_df = df_selected.groupBy(\"date\").count().orderBy(col(\"count\").desc()).limit(10)\n",
    "\n",
    "      # Join back to get tweets from top 10 dates only\n",
    "      df_top_dates = df_selected.join(top_dates_df.select(\"date\"), \"date\")\n",
    "\n",
    "      # Get top user per date\n",
    "      windowSpec = Window.partitionBy(\"date\").orderBy(col(\"count\").desc())\n",
    "      top_users_df = df_top_dates.groupBy(\"date\", \"user\").agg(count(\"id\").alias(\"count\")).withColumn(\"row_number\", row_number().over(windowSpec)).filter(col(\"row_number\") == 1).select(\"date\", \"user\")\n",
    "\n",
    "      # Collect result to driver\n",
    "      result = [(row.date, row.user) for row in top_users_df.collect()]\n",
    "\n",
    "      spark.stop()\n",
    "      return result\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2021, 2, 12), 'RanbirS00614606'),\n",
       " (datetime.date(2021, 2, 13), 'MaanDee08215437'),\n",
       " (datetime.date(2021, 2, 14), 'rebelpacifist'),\n",
       " (datetime.date(2021, 2, 15), 'jot__b'),\n",
       " (datetime.date(2021, 2, 16), 'jot__b'),\n",
       " (datetime.date(2021, 2, 17), 'RaaJVinderkaur'),\n",
       " (datetime.date(2021, 2, 18), 'neetuanjle_nitu'),\n",
       " (datetime.date(2021, 2, 19), 'Preetm91'),\n",
       " (datetime.date(2021, 2, 20), 'MangalJ23056160'),\n",
       " (datetime.date(2021, 2, 23), 'Surrypuria')]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_q1_spark = q1_time_spark(file_path)\n",
    "result_q1_spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.97 s ± 364 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit q1_time_spark(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "de_challenge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
