{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este archivo puedes escribir lo que estimes conveniente. Te recomendamos detallar tu solución y todas las suposiciones que estás considerando. Aquí puedes ejecutar las funciones que definiste en los otros archivos de la carpeta src, medir el tiempo, memoria, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file exists.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "file_path = r\"\\Users\\DZWorld2\\Documents\\Studying\\challenge_option\\tweets.json\\farmers-protest-tweets-2021-2-4.json\"\n",
    "# Ensure the file path is correctly formatted for Windows\n",
    "file_path = file_path.replace(\"\\\\\", \"/\")\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(file_path):\n",
    "    print(\"The file exists.\")\n",
    "else:\n",
    "    \n",
    "    print(\"The file does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "from collections import defaultdict, Counter\n",
    "from typing import List, Tuple, Generator, Dict\n",
    "# We this function to read the tweets from the file using a generator because im going to supose that the file is large and we dont want to load all the tweets into memory at once make it more memory efficient\n",
    "def read_tweets(file_path: str):\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            \n",
    "            yield json.loads(line)\n",
    "\n",
    "def q1_memory(file_path: str) -> List[Tuple[datetime.date, str, int]]:\n",
    "    tweet_counts_per_date = Counter()\n",
    "    user_tweets_per_date = defaultdict(lambda: Counter())\n",
    "\n",
    "    # Step 1 & 2: Read and process each tweet\n",
    "    for tweet in read_tweets(file_path):\n",
    "        date = datetime.strptime(tweet['date'], '%Y-%m-%dT%H:%M:%S%z').date()\n",
    "        user = tweet['user']['username']\n",
    "        tweet_counts_per_date[date] += 1\n",
    "        user_tweets_per_date[date][user] += 1\n",
    "\n",
    "    # Step 3 & 4: Identify top 10 dates\n",
    "    top_10_dates = [date for date, _ in tweet_counts_per_date.most_common(10)]\n",
    "\n",
    "    # Step 5: For each top date, find the user with the most tweets\n",
    "    top_users = [(date, user_tweets.most_common(1)[0][0], user_tweets.most_common(1)[0][1]) for date, user_tweets in user_tweets_per_date.items() if date in top_10_dates]\n",
    "\n",
    "    # Sort the result by date as the final step\n",
    "    top_users_sorted = sorted(top_users, key=lambda x: x[0])\n",
    "\n",
    "    return top_users_sorted\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(datetime.date(2021, 2, 12), 'RanbirS00614606', 176), (datetime.date(2021, 2, 13), 'MaanDee08215437', 178), (datetime.date(2021, 2, 14), 'rebelpacifist', 119), (datetime.date(2021, 2, 15), 'jot__b', 134), (datetime.date(2021, 2, 16), 'jot__b', 133), (datetime.date(2021, 2, 17), 'RaaJVinderkaur', 185), (datetime.date(2021, 2, 18), 'neetuanjle_nitu', 195), (datetime.date(2021, 2, 19), 'Preetm91', 267), (datetime.date(2021, 2, 20), 'MangalJ23056160', 108), (datetime.date(2021, 2, 23), 'Surrypuria', 135)]\n"
     ]
    }
   ],
   "source": [
    "print(q1_memory(file_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.q1_memory import q1_memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_q1_memory = q1_memory(file_path)\n",
    "result_q1_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.2 ns ± 0.709 ns per loop (mean ± std. dev. of 7 runs, 10,000,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit q1_memory.q1_memory(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peak memory: 461.33 MiB, increment: 1.70 MiB\n"
     ]
    }
   ],
   "source": [
    "%memit q1_memory(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def q1_time(file_path: str) -> List[Tuple[datetime.date, str, int]]:\n",
    "    try:\n",
    "        with open(file_path, 'r') as json_file:\n",
    "            # Cargar archivo json linea a linea\n",
    "            data = [json.loads(line.strip()) for line in json_file]\n",
    "        # Usar una list comprehension para extraer los campos\n",
    "        data = [(item['date'], item['user']['username'], item['id']) for item in data if 'date' in item and 'user' in item and 'id' in item and 'username' in item['user']]\n",
    "\n",
    "        # Convertir la lista de tuplas en un dataframe de pandas\n",
    "        df = pd.DataFrame(data, columns=['date', 'user', 'id'])\n",
    "        \n",
    "        # Convertir campo date en formato datetime\n",
    "        df['date'] = pd.to_datetime(df['date']).dt.date\n",
    "\n",
    "        tweet_counts = df.groupby('date').size()\n",
    "        top_10_dates = tweet_counts.nlargest(10).index\n",
    "        df_top_10 = df[df['date'].isin(top_10_dates)]\n",
    "        top_users = df_top_10.groupby('date')['user'].agg(lambda x: x.value_counts().index[0])\n",
    "\n",
    "        # Convertir el resultado en una lista de tuplas\n",
    "        result = [(date, user) for date, user in zip(top_10_dates, top_users)]\n",
    "        \n",
    "        return result\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: The file {file_path} was not found.\")\n",
    "        return []\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Error decoding JSON.\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(datetime.date(2021, 2, 12), 'RanbirS00614606'), (datetime.date(2021, 2, 13), 'MaanDee08215437'), (datetime.date(2021, 2, 17), 'rebelpacifist'), (datetime.date(2021, 2, 16), 'jot__b'), (datetime.date(2021, 2, 14), 'jot__b'), (datetime.date(2021, 2, 18), 'RaaJVinderkaur'), (datetime.date(2021, 2, 15), 'neetuanjle_nitu'), (datetime.date(2021, 2, 20), 'Preetm91'), (datetime.date(2021, 2, 23), 'MangalJ23056160'), (datetime.date(2021, 2, 19), 'Surrypuria')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "result_q1_fast = q1_time(file_path)\n",
    "print(result_q1_fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n"
     ]
    }
   ],
   "source": [
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.76 s ± 199 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit q1_time(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\n",
      "  Using cached pyspark-3.5.1-py2.py3-none-any.whl\n",
      "Collecting py4j==0.10.9.7\n",
      "  Using cached py4j-0.10.9.7-py2.py3-none-any.whl (200 kB)\n",
      "Installing collected packages: py4j, pyspark\n",
      "Successfully installed py4j-0.10.9.7 pyspark-3.5.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from datetime import date\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, to_date, count, row_number\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "def q1_time_spark(file_path: str) -> List[Tuple[date, str, int]]:\n",
    "    try:\n",
    "      # Initialize Spark session\n",
    "      spark = SparkSession.builder.appName(\"Q1Time\").getOrCreate()\n",
    "\n",
    "      # Read JSON file\n",
    "      df = spark.read.json(file_path)\n",
    "\n",
    "      # Filter out rows with missing fields\n",
    "      df_filtered = df.filter(\"date IS NOT NULL AND user IS NOT NULL AND id IS NOT NULL AND user.username IS NOT NULL\")\n",
    "\n",
    "      # Select and rename fields\n",
    "      df_selected = df_filtered.select(to_date(col(\"date\")).alias(\"date\"), col(\"user.username\").alias(\"user\"), col(\"id\"))\n",
    "\n",
    "      # Count tweets per date and get top 10 dates\n",
    "      top_dates_df = df_selected.groupBy(\"date\").count().orderBy(col(\"count\").desc()).limit(10)\n",
    "\n",
    "      # Join back to get tweets from top 10 dates only\n",
    "      df_top_dates = df_selected.join(top_dates_df.select(\"date\"), \"date\")\n",
    "\n",
    "      # Get top user per date\n",
    "      windowSpec = Window.partitionBy(\"date\").orderBy(col(\"count\").desc())\n",
    "      top_users_df = df_top_dates.groupBy(\"date\", \"user\").agg(count(\"id\").alias(\"count\")).withColumn(\"row_number\", row_number().over(windowSpec)).filter(col(\"row_number\") == 1).select(\"date\", \"user\")\n",
    "\n",
    "      # Collect result to driver\n",
    "      result = [(row.date, row.user) for row in top_users_df.collect()]\n",
    "\n",
    "      spark.stop()\n",
    "      return result\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected error occurred: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(datetime.date(2021, 2, 12), 'RanbirS00614606'),\n",
       " (datetime.date(2021, 2, 13), 'MaanDee08215437'),\n",
       " (datetime.date(2021, 2, 14), 'rebelpacifist'),\n",
       " (datetime.date(2021, 2, 15), 'jot__b'),\n",
       " (datetime.date(2021, 2, 16), 'jot__b'),\n",
       " (datetime.date(2021, 2, 17), 'RaaJVinderkaur'),\n",
       " (datetime.date(2021, 2, 18), 'neetuanjle_nitu'),\n",
       " (datetime.date(2021, 2, 19), 'Preetm91'),\n",
       " (datetime.date(2021, 2, 20), 'MangalJ23056160'),\n",
       " (datetime.date(2021, 2, 23), 'Surrypuria')]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_q1_spark = q1_time_spark(file_path)\n",
    "result_q1_spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.97 s ± 364 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit q1_time_spark(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from typing import List, Tuple\n",
    "import json\n",
    "import emoji\n",
    "\n",
    "def q2_memory(file_path: str) -> List[Tuple[str, int]]:\n",
    "    emoji_counter = Counter()\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            data = json.loads(line)\n",
    "            if 'content' in data:\n",
    "                # Use a generator expression for memory efficiency\n",
    "                emojis = (value.chars for value in emoji.analyze(data['content']))\n",
    "                emoji_counter.update(emojis)\n",
    "    top_10_emojis = emoji_counter.most_common(10)\n",
    "    return top_10_emojis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"\\Users\\DZWorld2\\Documents\\Studying\\challenge_option\\tweets.json\\farmers-protest-tweets-2021-2-4.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('🙏', 5049),\n",
       " ('😂', 3072),\n",
       " ('🚜', 2972),\n",
       " ('🌾', 2182),\n",
       " ('🇮🇳', 2086),\n",
       " ('🤣', 1668),\n",
       " ('✊', 1651),\n",
       " ('❤️', 1382),\n",
       " ('🙏🏻', 1317),\n",
       " ('💚', 1040)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_q2_memory = q2_memory(file_path)\n",
    "result_q2_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'emoji' has no attribute 'get_emoji_regexp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 33\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m top_10_emojis\u001b[38;5;241m.\u001b[39mto_dict(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecords\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m result_q2_time_pandas \u001b[38;5;241m=\u001b[39m \u001b[43mq2_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(result_q2_time_pandas)\n",
      "Cell \u001b[1;32mIn[15], line 20\u001b[0m, in \u001b[0;36mq2_pandas\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m     17\u001b[0m df \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnotnull()]\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Extract emojis from 'content'\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124memojis\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mextract_emojis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Flatten the list of emojis and create a Series\u001b[39;00m\n\u001b[0;32m     23\u001b[0m all_emojis \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries([emoji \u001b[38;5;28;01mfor\u001b[39;00m sublist \u001b[38;5;129;01min\u001b[39;00m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124memojis\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m emoji \u001b[38;5;129;01min\u001b[39;00m sublist])\n",
      "File \u001b[1;32mc:\\Users\\DZWorld2\\Documents\\Studying\\challenge_option\\challenge_DE\\de_challenge\\lib\\site-packages\\pandas\\core\\series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4800\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\DZWorld2\\Documents\\Studying\\challenge_option\\challenge_DE\\de_challenge\\lib\\site-packages\\pandas\\core\\apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\DZWorld2\\Documents\\Studying\\challenge_option\\challenge_DE\\de_challenge\\lib\\site-packages\\pandas\\core\\apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\DZWorld2\\Documents\\Studying\\challenge_option\\challenge_DE\\de_challenge\\lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\DZWorld2\\Documents\\Studying\\challenge_option\\challenge_DE\\de_challenge\\lib\\site-packages\\pandas\\core\\algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1747\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[15], line 20\u001b[0m, in \u001b[0;36mq2_pandas.<locals>.<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     17\u001b[0m df \u001b[38;5;241m=\u001b[39m df[df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnotnull()]\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Extract emojis from 'content'\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124memojis\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mextract_emojis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Flatten the list of emojis and create a Series\u001b[39;00m\n\u001b[0;32m     23\u001b[0m all_emojis \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries([emoji \u001b[38;5;28;01mfor\u001b[39;00m sublist \u001b[38;5;129;01min\u001b[39;00m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124memojis\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m emoji \u001b[38;5;129;01min\u001b[39;00m sublist])\n",
      "Cell \u001b[1;32mIn[15], line 7\u001b[0m, in \u001b[0;36mextract_emojis\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_emojis\u001b[39m(text):\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# Compile a regex for all emojis\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m     emoji_pattern \u001b[38;5;241m=\u001b[39m \u001b[43memoji\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_emoji_regexp\u001b[49m()\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# Find all emojis in the text\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m emoji_pattern\u001b[38;5;241m.\u001b[39mfindall(text)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'emoji' has no attribute 'get_emoji_regexp'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import emoji\n",
    "\n",
    "# Function to extract emojis from a text\n",
    "def extract_emojis(text):\n",
    "    # List to store found emojis\n",
    "    found_emojis = []\n",
    "    # Iterate over each character in the text\n",
    "    for char in text:\n",
    "        # Check if the character is an emoji\n",
    "        if emoji.is_emoji(char):\n",
    "            found_emojis.append(char)\n",
    "    return found_emojis\n",
    "\n",
    "# Main function to process the file and get top 10 emojis\n",
    "def q2_pandas(file_path):\n",
    "    # Read the file into a DataFrame\n",
    "    df = pd.read_json(file_path, lines=True)\n",
    "    \n",
    "    # Filter rows to ensure 'content' is not null\n",
    "    df = df[df['content'].notnull()]\n",
    "    \n",
    "    # Extract emojis from 'content'\n",
    "    df['emojis'] = df['content'].apply(extract_emojis)\n",
    "    \n",
    "    # Flatten the list of emojis and create a Series\n",
    "    all_emojis = pd.Series([emoji for sublist in df['emojis'] for emoji in sublist])\n",
    "    \n",
    "    # Count occurrences and get the top 10 emojis\n",
    "    top_10_emojis = all_emojis.value_counts().head(10).reset_index()\n",
    "    top_10_emojis.columns = ['emoji', 'count']\n",
    "    \n",
    "    return top_10_emojis.to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "de_challenge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
